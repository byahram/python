{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92480bcf-1052-4e20-81d0-e2377245e008",
   "metadata": {},
   "source": [
    "# 주피터 노트북"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ba79b-dc1e-44ec-a45d-ebfe0b98d678",
   "metadata": {},
   "source": [
    "### 아나콘다\n",
    "\n",
    "- 데이터 과학, 머신러닝, 인공지능 분야 등에서 사용한다.\n",
    "- conda : 가상환경과 패키지를 관리하는 도구이다.\n",
    "\n",
    "### Jupyter NoteBook\n",
    "\n",
    "- 웹브라우저에서 파이썬 코드를 실행하고 결과를 시각적으로 볼 수 있게 해주는 도구이다.\n",
    "\n",
    "### 주피터 노트북 \n",
    "\n",
    "-  내 컴퓨터에서 파이썬 공부를 하거나 실험할 때 좋다.\n",
    "    - 사용목적: 반복적 작업, 프로젝트 코드 작성에 적합\n",
    "\n",
    "### 구글 코랩\n",
    "\n",
    "- 인터넷만 있으면 어디서든 gpu 까지 써서 실습할 수 있다.\n",
    "    - 사용목적: 빠른 실험, 강의, 튜토리얼에 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca7f19-4d07-40e4-a987-cc5681dd5c8b",
   "metadata": {},
   "source": [
    "# 1. BeautifulSoup 기초 실습 : html.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5bab7b29-44b1-4349-bc86-0e0bf5a10761",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[BeautifulSoup]\n",
    "\n",
    "- HTML 및 xml 문서를 파싱(분석)하고, 원하는 데이터를 손쉽게 추출할 수 있게 도와주는 파이썬 라이브러리이다.\n",
    "- 웹 페이지에서 특정 태그, 클래스, ID 등을 기준으로 데이터를 검색하고 추출하는데 유용하며, 웹 크롤링과 웹 스크래핑을 할 때 자주 사용된다.\n",
    "'''\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "df6c7fd4-e586-4400-bfc0-01813a1bd33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "file_path = \"./웹크롤링.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1fc5498f-920a-4ef0-bae3-5a932ca45f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[HTML 파일 열기]\n",
    "\n",
    "- with open(...) as f : 파일을 열겠다.\n",
    "    -> r : 읽기 모드\n",
    "    -> w : 쓰기 전용(기존 파일은 지워짐)\n",
    "    -> a : 이어쓰기(append)\n",
    "\n",
    "[f.read()]\n",
    "\n",
    "- 파일 전체 내용을 한 번에 문장열로 읽어오는 것. 이 결과는 html 변수에 저장된다.\n",
    "'''\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f :\n",
    "    html = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6db6796b-e2c1-44c4-aaf1-8ea7061b98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[BeautifulSoup으로 파싱하는 법]\n",
    "\n",
    "1. html.parser : 문서를 구조적으로 해석하는 프로그램이다.\n",
    "2. lxml - 빠르다.\n",
    "3. html5lib - html5 기준으로 정밀하게 해석\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8500d334-ba13-45f9-a134-cddb86365e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 :  보이는 제목 \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[예제 1] 제목(h1) 태그 찾기\n",
    "'''\n",
    "\n",
    "title_tag = soup.find(\"h1\")\n",
    "print(\"제목 :\", title_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd912071-5a89-40b1-bc5b-a3080e871111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "할 일: 아침 먹기\n",
      "할 일: HTML 배우기\n",
      "할 일: 복습하기\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[예제 2] 목록(li) 전부 출력\n",
    "'''\n",
    "\n",
    "list_items = soup.find_all(\"li\")\n",
    "for item in list_items :\n",
    "    print(\"할 일:\", item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "42bc0fc6-0d30-472c-bd1a-16b99d474466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 주소: https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyNTAzMjlfMSAg%2FMDAxNzQzMjI1NjE0OTk2.kZ_6xaECjWK245yJIBTZB_gCGMAzN89e_p81l124gwMg.7uXEYKUSsDD2VDgeG6A5nAyWAg9QjNvzxKjaAa70iNUg.PNG%2F2a53f73b-eba8-4e58-9f82-86b34ebbae8f.png&type=sc960_832\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[예제 3] 이미지 주소 출력\n",
    "'''\n",
    "\n",
    "img_tag = soup.find(\"img\")\n",
    "print(\"이미지 주소:\", img_tag[\"src\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09012e3-6071-48c4-9d1a-a84af5c5c86e",
   "metadata": {},
   "source": [
    "# 2. BeautifulSoup 기초 실습 : html.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c941c6a5-86ac-4c82-9400-950f38e5a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[BeautifulSoup 기초 실습 : html.parser]\n",
    "\n",
    "- bs4 -> BeautifulSoup4의 약자이다.\n",
    "'''\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "668aab6f-8f81-4ed7-9337-982ec4b60ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- 웹 페이지에서 접속해서 HTML 문서를 가져오는 함수\n",
    "- urlopen()을 사용해서 웹사이트에 요청을 보냄\n",
    "- 받은 HTML 데이터를 BeautifulSoup으로 분석함\n",
    "- 원하는 태그나 정보를 꺼내서 쓸 수 있다.\n",
    "'''\n",
    "\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "59c3bcef-e501-471d-902b-f2a708043fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naver.com/\"\n",
    "\n",
    "'''\n",
    "[urlopen()]\n",
    "\n",
    "- 웹 사이트에 요청을 보내고, HTML 데이터를 받아오는 역할이다.\n",
    "'''\n",
    "\n",
    "page = urlopen(url)    # 웹사이트에 접속해서 HTML 데이터를 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fda71a4f-6962-444b-b6f0-8605674aebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>NAVER</title>\n",
      "NAVER\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[html.parser]\n",
    "\n",
    "- <head>, <body> 처럼 HTML 구조를 자동으로 읽고 구분해주는 역할을 한다.\n",
    "- HTML 문서는 그냥 텍스트 덩어리다.\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "# <title> 태그 전체를 출력\n",
    "print(soup.title)\n",
    "\n",
    "# <title> 안의 텍스트만 출력\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd424366-a07e-49c4-84aa-c42edf0d4840",
   "metadata": {},
   "source": [
    "# 3. BeautifulSoup 기초 실습 : lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bc987727-81ee-4db0-a886-6256248a4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9e4f42b1-43c3-4ca5-be71-d47dc5b07c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naver.com/\"\n",
    "\n",
    "page = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c607bc36-6840-49f3-bb2f-a3934cae8989",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Section 1. 웹 페이지에서 HTML 가져오기]\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2b8563c1-f683-484e-b33e-edcfba7885c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[HTML 샘플 직접 파싱하기]\n",
    "\n",
    "- 문자열로 구성된 HTML을 직접 BeautifulSoup 객체로 변환할 수 있다.\n",
    "- 이를 웹 연결 없이도 파싱 테스트가 가능하다.\n",
    "'''\n",
    "\n",
    "html = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title class=\"main-title\" id=\"page-title\">My Test Page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div class=\"content\">\n",
    "      <p class=\"text\">Hello, world!</p>\n",
    "      <p class=\"text\">Python is fun.</p>\n",
    "      <span id=\"note\">This is a note.</span>\n",
    "      <a href=\"https://example.com\" class=\"link\">Go to Example</a>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "16c7ae0e-f31c-467d-ac64-640967ff8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title class=\"main-title\" id=\"page-title\">My Test Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<div class=\"content\">\n",
      "<p class=\"text\">Hello, world!</p>\n",
      "<p class=\"text\">Python is fun.</p>\n",
      "<span id=\"note\">This is a note.</span>\n",
      "<a class=\"link\" href=\"https://example.com\">Go to Example</a>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "665fbc83-8bce-4b42-9bed-84178af3f209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title class=\"main-title\" id=\"page-title\">My Test Page</title>\n",
      "{'class': ['main-title'], 'id': 'page-title'}\n",
      "['main-title']\n",
      "page-title\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Section 2. title 태그 추출 및 속성 확인]\n",
    "\n",
    "- HTML 태그에는 id, class, name 등 다양한 속성이 포함되어 있을 수 있다.\n",
    "- \".attrs\"를 통해 해당 태그의 속성 전체를 딕셔너리 형태로 확인할 수 있으며,\n",
    "- 개별 속성은 딕셔너리처럼 접근하거나, \".get()\"으로 조회할 수 있다.\n",
    "'''\n",
    "\n",
    "tag_title = soup.title\n",
    "print(tag_title)\n",
    "print(tag_title.attrs)    # tag_title의 모든 속성 확인(딕셔너리 형태)\n",
    "print(tag_title[\"class\"])\n",
    "print(tag_title[\"id\"])\n",
    "\n",
    "# 예외 상황\n",
    "# print(tag_title[\"classss\"])  # 존재하지 않는 속성 조회 시, keyError 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2aa78db9-43a1-47b2-9d1c-99f40895ddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Test Page\n",
      "My Test Page\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Section 3. 텍스트 추출 방법 비교]\n",
    "\n",
    "- .text : 해당 태그 안의 모든 텍스트를 포함한 문자열 반환\n",
    "- .string : 해당 태그의 직접적인 텍스트만 반환하며, 자식 태그가 여러개면 \"None\"을 반환한다.\n",
    "'''\n",
    "\n",
    "print(tag_title.text)\n",
    "print(tag_title.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6dccdf5c-c9ad-4020-9f8c-2c49d03f6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[<span>이란?]\n",
    "\n",
    "- 짧은 텍스트나 요소를 묶을 때 사용하는 인라인 태그이다.\n",
    "- 의미는 없고, 디자인이나 특정 부분을 강조를 위해 사용\n",
    "- css 스타일, 색상, 클래스, ID 등을 적용할 때 주로 사용된다.\n",
    "'''\n",
    "\n",
    "html = \"\"\"<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\"\"\"\n",
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b767f79c-799b-49f2-8bd7-8180fc6a3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><span>test1</span><span>test2</span></p>\n",
      "text : test1test2\n",
      "string : None\n"
     ]
    }
   ],
   "source": [
    "# HTML 문서 안의 <p> 태그 하나를 찾아서 변수에 저장하는 코드\n",
    "tag_p = soup.p\n",
    "\n",
    "'''\n",
    "[.text]\n",
    "\n",
    "- 모든 자식 태그 안의 텍스트까지 몽땅 가져온다.\n",
    "\n",
    "[.string]\n",
    "\n",
    "- 태그 안에 순수한 문자열만 있는 경우 사용한다. \n",
    "- 자식이 1개 텍스트 일때만 텍스트 반환하고 아니면 None을 반환\n",
    "'''\n",
    "\n",
    "print(tag_p)\n",
    "print(\"text :\", tag_p.text)\n",
    "print(\"string :\", tag_p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3745d3c0-6f9b-47b3-a00f-384b0a04ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span>test1</span>, <span>test2</span>]\n",
      "<span>test1</span>\n",
      "<span>test2</span>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Section 4. 자식 요소 접근 : contents vs children]\n",
    "\n",
    "- .contents : 자식 요소들을 리스트 형태로 반환\n",
    "- .children : 자식 요소들을 이터레이터로 반환(반복문)\n",
    "'''\n",
    "\n",
    "tag_p_contents = soup.p.contents\n",
    "print(tag_p_contents)\n",
    "\n",
    "tag_p_children = soup.p.children\n",
    "for child in tag_p_children :\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "34a6dc8d-1cdf-412e-9231-b5c1db0a99d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><span>test1</span><span>test2</span></p>\n",
      "<head><title>test site</title></head>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[Section 5. 부모 및 조상 요소 접근]\n",
    "\n",
    "- .parent : 해당 태그의 부모 태그 반환\n",
    "- .parents : 해당 태그의 모든 조상 태그를 반복 가능한 객체로 반환\n",
    "'''\n",
    "\n",
    "tag_span = soup.span      # soup 에서 첫번째 <span> 태그를 가져와서 tag_span에 저장\n",
    "print(tag_span.parent)    # tag_span의 부모 태그를 출력 -> <p> 태그가 나올 것\n",
    "\n",
    "tag_title = soup.title    # soup에서 <title> 태그를 가져와서 tag_title에 저장\n",
    "print(tag_title.parent)   # tag_title의 부모 태그 출력 -> <head> 태그가 나올것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "456701a1-ace5-474e-a285-424e66d70b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><span>test1</span><span>test2</span></p>\n",
      "<body> <p><span>test1</span><span>test2</span></p> </body>\n",
      "<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\n",
      "<html> <head><title>test site</title></head> <body> <p><span>test1</span><span>test2</span></p> </body></html>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[tag_span이 속해 있는 모든 부모 태그를 거슬러 올라가며 출력]\n",
    "\n",
    "* 출력 순서\n",
    "    1. <p>\n",
    "    2. <body> -> <p>의 부모\n",
    "    3. <html> -> <body>의 부모\n",
    "    4. None -> <>\n",
    "'''\n",
    "\n",
    "for parent in tag_span.parents :\n",
    "    print(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffae6b3-5753-4c34-be0f-d476b3cb5c64",
   "metadata": {},
   "source": [
    "# 4. BeautifulSoup 기초 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "382d5ded-30a4-4628-a44c-4fcaf09eaadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3732f671-0c86-43df-b992-a639cf6c4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title class=\"main-title\" id=\"t-id\">Welcome to My Page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div>\n",
    "      <p class=\"desc\">오늘은 <span>파이썬</span>을 배우는 날입니다.</p>\n",
    "      <p class=\"desc\">HTML과 <span>BeautifulSoup</span>을 함께 배워요.</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "74ce441d-be01-42e6-bcb4-f50de490e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title class=\"main-title\" id=\"t-id\">Welcome to My Page</title>\n",
      "Welcome to My Page\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 1. title 태그 전체와 텍스트 출력]\n",
    "'''\n",
    "\n",
    "tag_title = soup.title\n",
    "print(tag_title)\n",
    "print(tag_title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "74546df8-af96-4fc4-b9a7-4c46b1591154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['main-title'], 'id': 't-id'}\n",
      "['main-title']\n",
      "t-id\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 2. title 태그의 속성 딕셔너리 출력]\n",
    "'''\n",
    "\n",
    "print(tag_title.attrs) \n",
    "print(tag_title[\"class\"])\n",
    "print(tag_title[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7a86d137-f547-4e6c-83d4-c232299b0e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: 오늘은 파이썬을 배우는 날입니다.\n",
      "string: None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 3. .text vs .string 차이 확인]\n",
    "'''\n",
    "\n",
    "tag_p = soup.p \n",
    "print(\"text:\", tag_p.text)\n",
    "print(\"string:\", tag_p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6b5423c4-180c-43ea-adf5-ce2fc97ae254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents: ['오늘은 ', <span>파이썬</span>, '을 배우는 날입니다.']\n",
      "child: 오늘은 \n",
      "child: <span>파이썬</span>\n",
      "child: 을 배우는 날입니다.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 4. 자식 요소 접근 (contents, children)]\n",
    "'''\n",
    "\n",
    "tag_p_contents = soup.p.contents\n",
    "print(\"contents:\", tag_p_contents)\n",
    "\n",
    "tag_p_children = soup.p.children\n",
    "for child in tag_p_children :\n",
    "    print(\"child:\", child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0e04d9c0-1cb0-4672-8d07-c3f0d7f9e5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부모: <p class=\"desc\">오늘은 <span>파이썬</span>을 배우는 날입니다.</p>\n",
      "부모 태그: p\n",
      "조상 태그들:\n",
      "- p\n",
      "- div\n",
      "- body\n",
      "- html\n",
      "- [document]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 5. 부모 및 조상 요소 접근]\n",
    "'''\n",
    "\n",
    "tag_span = soup.find(\"span\")\n",
    "print(\"부모:\", tag_span.parent)\n",
    "print(\"부모 태그:\", tag_span.parent.name)\n",
    "\n",
    "print(\"조상 태그들:\")\n",
    "for parent in tag_span.parents :\n",
    "    print(\"-\", parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a982f-2ec3-416b-9239-fe7f5081ab28",
   "metadata": {},
   "source": [
    "# 5. 네이버 뉴스 헤드라인 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "479c69f3-389f-4c0e-940a-6579fe45568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0a7550a5-39d4-4a36-969f-e106cb656d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대상 URL 1\n",
    "url = \"https://news.naver.com/section/103\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f2a2aad2-acc6-4ae4-8a03-912fa28a957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[요청 헤더 (봇 차단 방지용)]\n",
    "\n",
    "- 헤더 User-Agent와 같은 HTTP 요청을 보낼 때 함께 보내는 정보다.\n",
    "- 나 이런 환경에서 이걸 요청해! 브라우저는 이거고, 언어는 이거고, 쿠키는 이런걸 써\n",
    "- User_Agent : 어떤 브라우저(또는 프로그램)인지\n",
    "- Accept-Language : 선호하는 언어\n",
    "- Referer : 어디서 왔는지 (이전 페이지 주소)\n",
    "'''\n",
    "\n",
    "headers = {\"User-Agent\" : \"Mozilla/5.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6b2ebccb-21ef-4ff3-aaa7-30cef0649e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[headers = headers]\\n\\n- 요청할 때 같이 보낼 추가 정보들\\n- 나 이 주소 웹페이지 좀 열어줘! 나는 브라우저 처러 행동할거야 (User-Agent로)\\n- 그 웹사이트가 보내준 내용은 res에 담을게\\n'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 요청\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "'''\n",
    "[headers = headers]\n",
    "\n",
    "- 요청할 때 같이 보낼 추가 정보들\n",
    "- 나 이 주소 웹페이지 좀 열어줘! 나는 브라우저 처러 행동할거야 (User-Agent로)\n",
    "- 그 웹사이트가 보내준 내용은 res에 담을게\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "bc545e3f-09b6-4306-839e-e59ebc27d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 뉴스 헤드라인 목록\n",
      "1. 국가유산청, '마을 자연유산' 대국민 공모..\"자연유산 발굴\"\n",
      "2. 폭염 특보 수준 '무더위' 지속… 비, 언제 내리나?\n",
      "3. 롯데렌탈 유증에 소액주주 반기 \"시장가 대비 낮아, 권익 침해\"\n",
      "4. 임신·출산 반복하던 고양이의 최후... 아무리 자연의 순리라지만\n",
      "5. 결혼한 지 10년 넘은 주부의 밥상 고민\n",
      "6. “형 언제 돌아와?”…자식 잃은 부모 곁을 지킨 고양이\n",
      "7. 에어컨 없이 버텼던 이곳 여름, 예전 같지 않습니다만\n",
      "8. [날씨] '열돔'에 갇힌 한반도...일요일까지 '펄펄' 끓는다.\n",
      "9. 美 보조금 철회에도 현대차, 美서 전기차 증산했다\n",
      "10. 전미자동차노조 '관세 환영'에…\"韓 일자리 1만개 사라진다\"\n",
      "11. 7월초인데 40도 '역대급 폭염'...다음주 '찜통더위' 속 강한 비\n",
      "12. [자막뉴스] '두 겹' 이불 덮힌 한반도...\"중부지방 장마 다시 온다\"\n",
      "13. '서울시, 주택분 재산세 10% 늘었다'…강남3구, 전체의 절반\n",
      "14. 이번주 ‘땡볕 더위’ 계속…다음주 비 오고 ‘고온 다습’\n",
      "15. \"진정한 안티에이징은 피부가 아닌 내 몸이 젊어지는 것\"... 이광균 우리편한내과 원장 [인터뷰]\n",
      "16. “술 주님 말고, 진짜 주님을” 헛개차 한 병, 복음을 건네다\n",
      "17. [속보] 폭염에 온열질환자 작년 2.5배 급증…“증가 속도 역대 최고”\n",
      "18. “찜통더위에 온몸이 이글이글” 주말까지 계속…이후엔 수증기 유입 ‘폭염특보급’\n",
      "19. 혈당 조절하고 살 뺀다는 ‘이 음식들’ 먹었더니…오히려 독이 되는 경우?\n",
      "20. 면역력 저하된 암 환자, 폭염 속 건강 관리 ‘이렇게’\n",
      "21. 뜨거운 동풍 불며 서쪽 '펄펄'…주말까지 땡볕더위\n",
      "22. [날씨] 서쪽 폭염경보, 불볕더위 지속…온열질환 주의\n",
      "23. 한 침대 써야 잉꼬부부? 각자 푹 자는게 만족도 더 높아\n",
      "24. “아버지, 사망 직전까지 내 몸무게 걱정”… 결국 38kg 감량 보디빌딩 2위 수상, 방법은?\n",
      "25. 툭하면 배 아프다는데…소아 만성복통 병원 가야할까?\n",
      "26. EV4·아이오닉6 사이에 낀 4000만원대 BYD 씰…흥행 물음표\n",
      "27. [날씨] \"양산 꼭 쓰세요\"…서쪽지방 35도 안팎 가마솥 더위\n",
      "28. [날씨] 연일 밤낮없는 더위...한낮엔 또 펄펄, 서울 37℃\n",
      "29. 지금같은 '땡볕더위' 주말까지…하지만 이후에도 폭염특보급 무더위\n",
      "30. 이번 주말도 절절 끓는다…16∼17일 중부에 장맛비\n",
      "31. \"소변 보는데 몇 초 걸려요?\"…'이 시간' 넘기면 위험하다는 경고 나왔다 [헬스톡]\n",
      "32. “비누로도 안 씻겨” 노인 특유 냄새 ‘이것’ 때문?…과학적 이유 있다\n",
      "33. [센터웨더] 40도 육박 펄펄 끓는 더위…7월 초 기록적 폭염\n",
      "34. 중년 여성의 뱃살 빼기, ‘이것’ 덜 먹기부터\n",
      "35. 친구의 극단적 선택을 막기 위한 대화, 실패에서 시작되는 가능성\n",
      "36. [날씨] 서울 나흘째 폭염경보…곳곳 5~30mm 소나기\n",
      "37. 상반기 美 관세 장벽 뚫었지만…\"현대차 관세 비용 연간 3조\"\n",
      "38. [오후날씨 꿀팁] 서울 한낮 37도…서쪽 35도 안팎 폭염\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[enumerate(반복할 리스트, 시작 번호)]\n",
    "\n",
    "- 반복할 리스트 : 순회하려는 리스트나 튜플\n",
    "- 시작번호(선택) : 번호를 몇번부터 시작할 지 지정(기본은 0, 보통은 1부터 많이 쓴다.)\n",
    "\n",
    "[strip=True]\n",
    "\n",
    "- 태그.get_text(strip=True) : html 태그 안에서 텍스트만 깔끔하게 추출할 때 사용한다.\n",
    "- 웹 페이지에서는 글자 앞 뒤에 보이지 않는 띄어쓰기나 줄 바꿈이 있을 수 있다.\n",
    "- 우리가 뉴스 제목처럼 깔끔하게 출력하고 싶을 땐 strip=True를 넣어서 공백을 제거한다.\n",
    "'''\n",
    "\n",
    "# 응답이 성공적일 때\n",
    "if response.status_code == 200 :\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # 모든 strong.sa_text_strong 요소 선택 (제목이 들어 있다.)\n",
    "    tag_titles = soup.select(\"div.sa_text strong.sa_text_strong\")\n",
    "\n",
    "    print(\"전체 뉴스 헤드라인 목록\")\n",
    "    for i, tag in enumerate(tag_titles, 1) :\n",
    "        print(f\"{i}. {tag.get_text(strip=True)}\")\n",
    "\n",
    "else :\n",
    "    print(\"요청 실패 :\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b9844b6b-2003-4925-a1b7-50dffc210779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 뉴스 헤드라인 목록\n",
      "1. 넷마블 자회사 직원, 게임 아이템 비정상 유통…500만원 부당이익\n",
      "2. LG CNS, 추론형 LLM 개발…23개 언어 지원\n",
      "3. 삼성 노태문 \"올해 말까지 4억대 기기에 '갤럭시 AI' 탑재\"\n",
      "4. \"4만 中企 보안 진입장벽 낮춘다\"…SK쉴더스 '특화구독' 제공\n",
      "5. 식물은 어떻게 폭염에도 살아남나…유전자 조절 원리 밝혀\n",
      "6. 삼성전자, ‘갤럭시 워치8·워치8 클래식’ 공개…전작 대비 11% 얇아진 두께\n",
      "7. 우주항공청, 우주산업 확대위한 국제협력 강화\n",
      "8. 이용자 개인정보 털린 블랙야크에 개보위, 과징금 14억 부과\n",
      "9. \"갤럭시 S25 사면 30만원 드려요”.. 통신사 간 고객 유치 경쟁 후끈 [1일IT템]\n",
      "10. 비공개글 AI 학습 제외…네이버 약관 바꿨다\n",
      "11. 한화오션, 폭염 대비 직원 보호 총력…냉방버스 출동\n",
      "12. 미세먼지 없애려다 폭염 심해진다? 에어로졸의 '기후역설'\n",
      "13. [뉴스줌인] 엔비디아 기록적 성장 배경은 '생태계'\n",
      "14. 눈 크게 뜬 ‘우주 올빼미’ 등장…제임스웹 포착 [우주로 간다]\n",
      "15. 김승연 회장의 이글스 사랑...스테이크·에어팟으로 격려\n",
      "16. 동아에스티, GLP-1 이중작용 비만약 추가 임상 1상 진입\n",
      "17. HLB생명과학 임시주총서 'HLB와 합병안' 통과\n",
      "18. 전기차 오너 10명 중 9명 \"다음 차도 전기차 사겠다\"\n",
      "19. 넷마블 자회사 직원, 게임 아이템 비정상 유통…500만원 부당이익\n",
      "20. 'RF 온라인 넥스트'서 고가 아이템 생성해 현금화한 직원 '덜미'\n",
      "21. LG화학, 경구용 희귀비만증신약 ‘비바멜라곤’ 임상3상 진입 청신호\n",
      "22. “첫 달 요금 무료”…이통 3사, 무약정 온라인 요금제로 경쟁 확전\n",
      "23. 도우인시스, 폴더블향 UTG 양산라인 증설 박차…삼성·美 잠재 고객사 대응\n",
      "24. LG화학, 희소비만질환 먹는약 '비바멜라곤' 2상서 BMI 감소 확인\n",
      "25. '복붙' AI 콘텐츠에 칼 빼 든 유튜브…\"수익 창출 불가\"\n",
      "26. 삼성D, 애플 폴더블 라인 구축…2년 독점 공급\n",
      "27. 온열질환자 벌써 1200명 넘었다…'예년 2.5배' 속도도 발생\n",
      "28. 지구 온난화 때문에 백두산 폭발하나? [달콤한 사이언스]\n",
      "29. [현장]반으로 '접힌' 삼성전자 영업이익...엑시노스 AP가 구원 투수 되나\n",
      "30. KT, 데이터 함께 쓰는 로밍 420만 돌파\n",
      "31. 먹을 수 없는 '개미' 음식으로 1억2000만원 번 식당 적발\n",
      "32. “콘칩 봉지보다 가볍다”…뉴욕서 베일 벗은 갤럭시Z 폴드7\n",
      "33. '숨 약간 가빠지는' 중강도 이상 운동하는 성인, 4명 중 1명 뿐\n",
      "34. 비만·당뇨·치매…\"병 이름만 바꿔도 환자에 큰 힘 된다\" 새 이름은?\n",
      "35. 휴머노이드, 피지컬AI 달고 훨훨 나는데…국내 인재·데이터 부족\n",
      "36. 김유원 네이버클라우드 대표, “글로벌 시장 개척 본격화…AI·클라우드 사업 사활”\n",
      "37. \"라인야후 사태 영향 없다\"…김유원 대표, 라인웍스 독립성 강조(종합)\n",
      "38. 'AI가 바꾼 기업가치'…엔비디아, 세계 첫 시총 '4조 달러'\n",
      "39. 올 여름철 최대 전력수요 97.8GW 가능성…전력당국 안정적 전력수급 총력\n",
      "40. \"모든 곳에 '제로트러스트+AI' 보안\"…韓 시장 확대 노리는 '지스케일러'\n",
      "41. 폴드7·플립7 왜 화제?…AI 기능 보고 놀랐다\n",
      "42. 스마트폰 시장서 고전하는 소니…\"LG 말고 모토로라 따르라\"\n",
      "43. '러브버그 학살 멈춰달라' 눈물 호소한 환경운동가, 알고보니 가짜\n",
      "44. ‘키 10㎝’ 꼬마 벼 개발…“지구 밖 농사에 딱”\n"
     ]
    }
   ],
   "source": [
    "# 대상 URL 2\n",
    "url = \"https://news.naver.com/section/105\"\n",
    "\n",
    "headers = {\"User-Agent\" : \"Mozilla/5.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200 :\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    title_tags = soup.select(\"div.sa_text strong.sa_text_strong\")\n",
    "\n",
    "    print(\"전체 뉴스 헤드라인 목록\")\n",
    "    for i, tag in enumerate(title_tags, 1) :\n",
    "        print(f\"{i}. {tag.get_text(strip=True)}\")\n",
    "\n",
    "else :\n",
    "    print(\"요청 실패 :\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52439b14-504a-454e-b5e2-b860f86a8425",
   "metadata": {},
   "source": [
    "# 6. 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "90021d88-fe97-4e9b-bbb1-116debe6d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2b6b7bd2-1afc-4122-8578-f3f68d76cab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title class=\"main-title\" id=\"t-id\">Movie Review - April</title>\n",
      "</head>\n",
      "<body>\n",
      "<div>\n",
      "<p class=\"desc\">어제 본 영화는 <span>인셉션</span>이었습니다.</p>\n",
      "<p class=\"desc\">가장 인상 깊었던 장면은 <span>중력 무중력 액션</span>이에요.</p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title class=\"main-title\" id=\"t-id\">Movie Review - April</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <div>\n",
    "      <p class=\"desc\">어제 본 영화는 <span>인셉션</span>이었습니다.</p>\n",
    "      <p class=\"desc\">가장 인상 깊었던 장면은 <span>중력 무중력 액션</span>이에요.</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9a2b8bce-6c4a-4333-9b1b-c1c2d156681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title class=\"main-title\" id=\"t-id\">Movie Review - April</title>\n",
      "Movie Review - April\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 1. title 태그 전체와 텍스트 출력]\n",
    "'''\n",
    "\n",
    "tag_title = soup.title\n",
    "print(tag_title)\n",
    "print(tag_title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ebf94e9a-7688-46ec-96cb-6a9201039836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['main-title'], 'id': 't-id'}\n",
      "['main-title']\n",
      "t-id\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 2. title 태그의 속성 딕셔너리 출력]\n",
    "'''\n",
    "\n",
    "print(tag_title.attrs) \n",
    "print(tag_title[\"class\"])\n",
    "print(tag_title[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2c576288-e579-4ccf-bef7-9e7e73ea4ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: 어제 본 영화는 인셉션이었습니다.\n",
      "string: None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 3 .text vs .string]\n",
    "'''\n",
    "\n",
    "tag_p = soup.p \n",
    "print(\"text:\", tag_p.text)\n",
    "print(\"string:\", tag_p.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "529d34f5-e3b4-4ce4-b498-d2ca9e4f2594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents: ['어제 본 영화는 ', <span>인셉션</span>, '이었습니다.']\n",
      "child: 어제 본 영화는 \n",
      "child: <span>인셉션</span>\n",
      "child: 이었습니다.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 4. 자식 요소 접근]\n",
    "'''\n",
    "\n",
    "tag_p_contents = soup.p.contents\n",
    "print(\"contents:\", tag_p_contents)\n",
    "\n",
    "tag_p_children = soup.p.children\n",
    "for child in tag_p_children :\n",
    "    print(\"child:\", child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8234a88c-4a6b-4d72-a0a2-dc08540c1104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부모: <p class=\"desc\">어제 본 영화는 <span>인셉션</span>이었습니다.</p>\n",
      "부모 태그: p\n",
      "조상 태그들:\n",
      "- p\n",
      "- div\n",
      "- body\n",
      "- html\n",
      "- [document]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[문제 5. 부모 및 조상 요소 접근]\n",
    "'''\n",
    "\n",
    "tag_span = soup.find(\"span\")\n",
    "print(\"부모:\", tag_span.parent)\n",
    "print(\"부모 태그:\", tag_span.parent.name)\n",
    "\n",
    "print(\"조상 태그들:\")\n",
    "for parent in tag_span.parents :\n",
    "    print(\"-\", parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b9eef-aed9-41a8-a5fe-9f4a78fb91b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
